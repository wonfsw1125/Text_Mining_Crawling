{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# openAI API key 받기\n",
    "- https://platform.openai.com/api-keys 접속 후 로그인\n",
    "- create new secret key 진행\n",
    "- 생성된 secret key 복사 (요금이 청구되므로 유출되지 않도록 주의! 유출되었다면 기존 키를 폐기하고 새로운 키를 받을 것)\n",
    "- https://platform.openai.com/settings/organization/billing/overview 에 들어가 가격을 결제할 것\n",
    "\n",
    "- 자세한 사용법은 https://github.com/openai/openai-python 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import openai\n",
    "import os\n",
    "\n",
    "\n",
    "api_key = \"your api key here\"\n",
    "client = openai.OpenAI(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slipperiness of ice is primarily due to the thin layer of liquid water that forms on its surface. When pressure is applied, such as the weight of a person's foot, the ice can melt slightly, creating a thin layer of water. This liquid water acts as a lubricant, reducing the friction between the ice and the object moving across it, making it slippery. This phenomenon is known as \"pressure melting\" and is what causes ice to be slippery even when temperatures are below freezing."
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"I am a Ph.D. in physics\"},\n",
    "        {\"role\": \"user\", \"content\": \"Why is the ice slippery?\"}\n",
    "    ],\n",
    "    stream=True)\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ice is slippery because when you step on it, the pressure from your weight melts the top layer of the ice just a little bit. This creates a thin layer of water on the surface, which makes it slippery for you to walk on. It's like how a banana peel can make a floor slippery because it releases a thin layer of oil when you step on it."
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\" : \"system\", \"content\" : \"I am five-years old\"},\n",
    "        {\"role\" : \"user\", \"content\" : \"Why is the ice slippery?\"}\n",
    "    ],\n",
    "    stream=True)\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slipperiness of ice can be attributed to the thin layer of water that forms on its surface. When you step on ice, the pressure exerted by your weight can cause a small amount of ice to melt, creating a thin layer of water between the ice and your foot. This thin layer of water significantly reduces the friction between your foot and the ice, making it slippery. The low friction coefficient of ice combined with this thin layer of water results in the slippery nature of ice."
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\" : \"system\", \"content\" : \"I am a Ph.D. in physics\"},\n",
    "        {\"role\" : \"user\", \"content\" : \"Why is the ice slippery?\"},\n",
    "        {\"role\" : \"assistant\", \"content\" : \"We are learning about friction force.\"}\n",
    "    ],\n",
    "    stream=True)\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would need more information to determine who the murderer is. Can you provide me with some details about the case or the events leading up to the murder?"
     ]
    }
   ],
   "source": [
    "question = \"There is Jack, John, and Jane. Who is the murderer?\"\n",
    "search_result = search_documents(question)\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\" : \"system\", \"content\" : \"You are a detective\"},\n",
    "        {\"role\" : \"user\", \"content\" : question}\n",
    "    ],\n",
    "    stream=True)\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the information I found, it appears that Jack is the murderer. Is there anything else you would like to know or discuss about this case?"
     ]
    }
   ],
   "source": [
    "retrieve = {\"Jack\": \"He is the murderer.\",\n",
    "            \"John\": \"He is innocent.\",\n",
    "            \"Jane\": \"She is innocent.\"}\n",
    "\n",
    "def search_documents(question):\n",
    "    for key in retrieve:\n",
    "        if key.lower() in question.lower():\n",
    "            return retrieve[key]\n",
    "    return \"No relevant information found.\"\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a detective\"},\n",
    "        {\"role\": \"user\", \"content\": question},\n",
    "        {\"role\": \"system\", \"content\": \"Search result: {}\".format(search_result)}\n",
    "    ],\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "- https://platform.openai.com/docs/guides/fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# 최소 10개의 메시지 필요\n",
    "# 메시지 형식 준수\n",
    "\n",
    "data = [\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Ronaldo, Messi, and Neymar, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Messi\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Ronaldo, Neymar, and Benzema, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Ronaldo\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Neymar, Benzema, and Lewandowski, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Neymar\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Benzema, Kane, and Lewandowski, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Lewandowski\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Benzema, Kane, and Suarez, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Benzema\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Modric, Kane, and Suarez, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Modric\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Henry, Kane, and Suarez, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Henry\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Bale, Kane, and Suarez, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Suarez\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Bale, Kane, and Salah, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Bale\"}\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a football scout.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Among Son, Kane, and Salah, who is the best?\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Kane\"}\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "with open('finetuning_data.jsonl', 'w', encoding='utf-8-sig') as json_file:\n",
    "    for item in data:\n",
    "        json_file.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'file-TMgDqtMwOBTQrlN58rDnhADG'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploaded_file = client.files.create(file=open(\"finetuning_data.jsonl\", \"rb\"), purpose=\"fine-tune\")\n",
    "file_id = uploaded_file.id\n",
    "file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJobEvent(id='ftevent-2Zkk8RbQzI91FvO9Qvp2jiZY', created_at=1725400041, level='info', message='Validating training file: file-TMgDqtMwOBTQrlN58rDnhADG', object='fine_tuning.job.event', data={}, type='message')\n",
      "FineTuningJobEvent(id='ftevent-RWX5Hqn5lVUSoadnRYsh2NvD', created_at=1725400041, level='info', message='Created fine-tuning job: ftjob-aNJfQdQrVEpjKhtXOskHc5CG', object='fine_tuning.job.event', data={}, type='message')\n"
     ]
    }
   ],
   "source": [
    "fine_tune_job = client.fine_tuning.jobs.create(training_file=file_id, model=\"gpt-3.5-turbo\")\n",
    "fine_tune_job_id = fine_tune_job.id\n",
    "events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=fine_tune_job_id, limit=10)\n",
    "for event in events.data:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n"
     ]
    }
   ],
   "source": [
    "# 업로드 상태 확인\n",
    "fine_tune_job = client.fine_tuning.jobs.retrieve(fine_tune_job_id)\n",
    "print(fine_tune_job.status)  # 'succeeded' 또는 'failed'\n",
    "fine_tuned_model_id = fine_tune_job.fine_tuned_model  # 파인튜닝된 모델의 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJobEvent(id='ftevent-jKUqPRTrfgVpx13R9Ag75P52', created_at=1725402023, level='info', message='Step 37/100: training loss=0.00', object='fine_tuning.job.event', data={'step': 37, 'train_loss': 0.00246429443359375, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics')\n",
      "FineTuningJobEvent(id='ftevent-W0UscZoEORXDRbIqQH2k8wse', created_at=1725402019, level='info', message='Step 36/100: training loss=0.93', object='fine_tuning.job.event', data={'step': 36, 'train_loss': 0.926629364490509, 'total_steps': 100, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics')\n",
      "FineTuningJobEvent(id='ftevent-22lHYNe9itDJBlRx9jL5Hlqp', created_at=1725402019, level='info', message='Step 35/100: training loss=1.47', object='fine_tuning.job.event', data={'step': 35, 'train_loss': 1.466423511505127, 'total_steps': 100, 'train_mean_token_accuracy': 0.75}, type='metrics')\n",
      "FineTuningJobEvent(id='ftevent-Vlv8037aCrJIA2JkUtN3Yen0', created_at=1725402019, level='info', message='Step 34/100: training loss=0.62', object='fine_tuning.job.event', data={'step': 34, 'train_loss': 0.6159577369689941, 'total_steps': 100, 'train_mean_token_accuracy': 0.75}, type='metrics')\n",
      "FineTuningJobEvent(id='ftevent-V8jkrCb8eGxavZn2CBmPQVeJ', created_at=1725402016, level='info', message='Step 33/100: training loss=0.00', object='fine_tuning.job.event', data={'step': 33, 'train_loss': 9.765625145519152e-05, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics')\n",
      "FineTuningJobEvent(id='ftevent-nVs5fVxjtCShOvgBN5fEGAXI', created_at=1725402013, level='info', message='Step 32/100: training loss=0.00', object='fine_tuning.job.event', data={'step': 32, 'train_loss': 0.0001583099365234375, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics')\n",
      "FineTuningJobEvent(id='ftevent-zlGk7MtFCckMv3Oxw6hWgdCa', created_at=1725402013, level='info', message='Step 31/100: training loss=0.00', object='fine_tuning.job.event', data={'step': 31, 'train_loss': 0.004460811614990234, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics')\n",
      "FineTuningJobEvent(id='ftevent-7b9xtlN5ip9Krq8qGO0oC0rp', created_at=1725402010, level='info', message='Step 30/100: training loss=1.04', object='fine_tuning.job.event', data={'step': 30, 'train_loss': 1.0353732109069824, 'total_steps': 100, 'train_mean_token_accuracy': 0.75}, type='metrics')\n",
      "FineTuningJobEvent(id='ftevent-ZPQeIfJ38bSFTi3UPRv2nnra', created_at=1725402002, level='info', message='Step 29/100: training loss=0.01', object='fine_tuning.job.event', data={'step': 29, 'train_loss': 0.010538101196289062, 'total_steps': 100, 'train_mean_token_accuracy': 1.0}, type='metrics')\n",
      "FineTuningJobEvent(id='ftevent-7pWN7Nfwo20zTCY73vDgTPDZ', created_at=1725401998, level='info', message='Step 28/100: training loss=2.01', object='fine_tuning.job.event', data={'step': 28, 'train_loss': 2.0122110843658447, 'total_steps': 100, 'train_mean_token_accuracy': 0.8333333134651184}, type='metrics')\n"
     ]
    }
   ],
   "source": [
    "events = client.fine_tuning.jobs.list_events(fine_tuning_job_id=fine_tune_job_id, limit=10)\n",
    "for event in events.data:\n",
    "    print(event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messi"
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model= \"ft:gpt-3.5-turbo-0125:personal::A3WDgJPH\",\n",
    "    messages=[\n",
    "        {\"role\" : \"system\", \"content\" : \"You are a football scout.\"},\n",
    "        {\"role\" : \"user\", \"content\" : \"Among Messi, Maradona, and Pele, who is the best?\"}\n",
    "    ],\n",
    "    stream=True)\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "finetuned_model = \"ft:gpt-3.5-turbo-0125:personal::A3WDgJPH\"\n",
    "with open(file='finetuned_model.pickle', mode='wb') as f:\n",
    "    pickle.dump(finetuned_model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kane"
     ]
    }
   ],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model= \"ft:gpt-3.5-turbo-0125:personal::A3WDgJPH\",\n",
    "    messages=[\n",
    "        {\"role\" : \"system\", \"content\" : \"You are a football scout.\"},\n",
    "        {\"role\" : \"user\", \"content\" : \"Among Son, Salah, and Kane, who is the best?\"}\n",
    "    ],\n",
    "    stream=True)\n",
    "\n",
    "for chunk in stream:\n",
    "    print(chunk.choices[0].delta.content or \"\", end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
